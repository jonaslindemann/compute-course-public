{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonaslindemann/compute-course-public/blob/master/general/2025/Python_built_in_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OODwR6sIk555"
      },
      "source": [
        "<img src=\"https://github.com/jonaslindemann/compute-course-docs/blob/2b815899b4ff728c42dd330e0853412efb12e075/source/images/builtin_functions.png?raw=true\" alt=\"Alt text\" width=\"600\">\n",
        "\n",
        "# Python Built-in Functions and Runtime Library\n",
        "\n",
        "This notebook provides a comprehensive guide to Python's built-in functions and runtime library. You'll learn how to interact with the operating system, manage files and directories, execute external programs, handle logging, and work with various data formats.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. **System Functions**\n",
        "   - Environment Variables\n",
        "   - System Path Management\n",
        "   - Working Directory Operations\n",
        "   - File and Directory Listing\n",
        "   - Directory Manipulation\n",
        "   - File Information Queries\n",
        "   - Path Management with `os.path` and `pathlib`\n",
        "   - Temporary Files\n",
        "\n",
        "2. **Process Management**\n",
        "   - Executing External Programs\n",
        "   - Subprocess Module\n",
        "   - Process Communication and Control\n",
        "\n",
        "3. **Logging**\n",
        "   - Basic Logging\n",
        "   - Custom Loggers\n",
        "   - Log Formatting\n",
        "\n",
        "4. **Data Serialization**\n",
        "   - JSON Format\n",
        "   - Pickle Format\n",
        "   - Data Persistence Best Practices\n",
        "\n",
        "5. **Data Archiving and Compression**\n",
        "   - TAR Files\n",
        "   - ZIP Files\n",
        "   - Compression Techniques\n",
        "\n",
        "6. **Special File Formats**\n",
        "   - Configuration Files (INI)\n",
        "   - CSV Files\n",
        "   - Advanced File Processing\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "- Interact with the operating system using Python\n",
        "- Manage files and directories programmatically\n",
        "- Execute and control external processes\n",
        "- Implement structured logging in applications\n",
        "- Serialize and deserialize data in various formats\n",
        "- Work with compressed archives and special file formats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwPxLTHlvWzE"
      },
      "source": [
        "---\n",
        "# System functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgZp8PEvk558"
      },
      "source": [
        "## Environment variables\n",
        "\n",
        "Environment variables are variables defined in the operating environment. Users can modify these to control behavior of applications and software. In Python the dirctionary os.environ contains these variables.\n",
        "\n",
        "To safely access the environ dictionary we use the .get() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLE-Divnk55-",
        "outputId": "90d9b417-4432-4425-f6c0-54c1236a3afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PATH: /opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"PATH:\", os.environ.get(\"PATH\", \"PATH not found\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can iterate over the envion dictionary just like any dictionary."
      ],
      "metadata": {
        "id": "bsYzO-o8wHvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 5 environment variables:\")\n",
        "\n",
        "for i, (variable, value) in enumerate(os.environ.items()):\n",
        "    if i < 5:\n",
        "        print(f\"{variable} = {value[:50]}{'...' if len(value) > 50 else ''}\")\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Ul0Gw6vqYr",
        "outputId": "4ca37f58-56ac-4031-9fb7-f8e082733290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 environment variables:\n",
            "SHELL = /bin/bash\n",
            "NV_LIBCUBLAS_VERSION = 12.5.3.2-1\n",
            "NVIDIA_VISIBLE_DEVICES = all\n",
            "COLAB_JUPYTER_TRANSPORT = ipc\n",
            "NV_NVML_DEV_VERSION = 12.5.82-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the Python len() method to query the number of environment variables"
      ],
      "metadata": {
        "id": "UC3yESURwUS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTotal environment variables: {len(os.environ)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stBUekKtvtBL",
        "outputId": "6c1ef917-6922-431b-fd88-961e66eeb965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total environment variables: 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also define new environment variables in the current process in the same way as we assign new items to a dictionary."
      ],
      "metadata": {
        "id": "PD-IPuOHwhdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting and getting custom environment variables\n",
        "os.environ[\"PYTHON_COURSE_DEMO\"] = \"Hello from Python!\"\n",
        "print(f\"\\nCustom variable: {os.environ.get('PYTHON_COURSE_DEMO')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn_6pChJvwjO",
        "outputId": "2cb30f04-ea2a-4bc8-e583-e7e3e1a384cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom variable: Hello from Python!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is good practice to check if a variable exists before accessing it. We use the `in` operator in Python to accomplish this."
      ],
      "metadata": {
        "id": "Fp8CnZRowtws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"HOME\" in os.environ:\n",
        "    print(f\"Home directory: {os.environ['HOME']}\")\n",
        "elif \"USERPROFILE\" in os.environ:  # Windows equivalent\n",
        "    print(f\"User profile: {os.environ['USERPROFILE']}\")\n",
        "else:\n",
        "    print(\"Home directory not found in environment variables\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXwgjVh4vyi1",
        "outputId": "fb5e647c-de02-463c-d601-087176407086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Home directory: /root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy2lZ_fik56J"
      },
      "source": [
        "## Accessing the system path\n",
        "\n",
        "The system path controls how the operating system searches for executables in the file system. Python has a neutral way of querying these from the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq1uC5Csk56L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa33cc10-a80b-4f4d-d712-f0ca756cf2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin\n",
            "/usr/local/nvidia/bin\n",
            "/usr/local/cuda/bin\n",
            "/usr/local/sbin\n",
            "/usr/local/bin\n",
            "/usr/sbin\n",
            "/usr/bin\n",
            "/sbin\n",
            "/bin\n",
            "/tools/node/bin\n",
            "/tools/google-cloud-sdk/bin\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "exe_path_list = os.get_exec_path()\n",
        "\n",
        "for path in exe_path_list:\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flytb4lfk56Q"
      },
      "source": [
        "## Changing and querying the working directory\n",
        "\n",
        "The working directory is the directory where your application is started. Python has functions for changing and querying the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvvVK01Fk56a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a64afc-43a0-4a6e-f3f4-2f21f41c690f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n",
        "\n",
        "os.chdir(\"..\")\n",
        "print(os.getcwd())\n",
        "os.chdir(cwd)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nM_Xp8xk56e"
      },
      "source": [
        "## Listing files in a directory\n",
        "\n",
        "For many applications it can be important to query what files and directories are available. The `os.listdir()` function implements this in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzDd_3FHGQPh"
      },
      "outputs": [],
      "source": [
        "# Create a test file using Python (cross-platform)\n",
        "with open(\"testfile\", \"w\") as f:\n",
        "    f.write(\"This is a test file created by Python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujHpvBdyk56g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8074caa1-7231-49b2-8a49-319e11dd2193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "testfile\n",
            "sample_data\n",
            "Katalog: .config\n",
            "Fil    : testfile\n",
            "Katalog: sample_data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for item in os.listdir():\n",
        "    print(item)\n",
        "\n",
        "for item in os.listdir():\n",
        "    if os.path.isdir(item):\n",
        "        print(\"Katalog:\", item)\n",
        "    if os.path.isfile(item):\n",
        "        print(\"Fil    :\", item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW2guNh1k56k"
      },
      "source": [
        "## Directory manipulation\n",
        "\n",
        "Python also has a lot of functions for creating and manipulating directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvxAe9ujk56n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ec18a6-6621-4703-d9dc-74662a5368a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed to: /content/demo_directory\n",
            "Directory contents after creation:\n",
            "  📁 Directory: testdir\n",
            "  📄 File: testfile.txt (20 bytes)\n",
            "\n",
            "Directory contents after rename:\n",
            "  testdir\n",
            "  renamed_testfile.txt\n",
            "\n",
            "Directory contents after cleanup:\n",
            "  Items remaining: 0\n",
            "Demo directory removed\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Store current directory for cleanup\n",
        "cwd = os.getcwd()\n",
        "\n",
        "try:\n",
        "    # Create directory if it doesn't exist\n",
        "\n",
        "    test_dir = Path(\"demo_directory\")\n",
        "    test_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Change to the new directory\n",
        "\n",
        "    os.chdir(test_dir)\n",
        "    print(f\"Changed to: {os.getcwd()}\")\n",
        "\n",
        "    # Create subdirectory and file\n",
        "\n",
        "    subdir = Path(\"testdir\")\n",
        "    subdir.mkdir(exist_ok=True)\n",
        "\n",
        "    test_file = Path(\"testfile.txt\")\n",
        "    test_file.write_text(\"This is test content\")\n",
        "\n",
        "    print(\"Directory contents after creation:\")\n",
        "    for item in os.listdir():\n",
        "        item_path = Path(item)\n",
        "        if item_path.is_dir():\n",
        "            print(f\"  📁 Directory: {item}\")\n",
        "        else:\n",
        "            print(f\"  📄 File: {item} ({item_path.stat().st_size} bytes)\")\n",
        "\n",
        "    # Rename the file\n",
        "\n",
        "    new_name = Path(\"renamed_testfile.txt\")\n",
        "    test_file.rename(new_name)\n",
        "\n",
        "    print(\"\\nDirectory contents after rename:\")\n",
        "    for item in os.listdir():\n",
        "        print(f\"  {item}\")\n",
        "\n",
        "    # Cleanup\n",
        "\n",
        "    new_name.unlink()  # Remove file\n",
        "    subdir.rmdir()     # Remove empty directory\n",
        "\n",
        "    print(\"\\nDirectory contents after cleanup:\")\n",
        "    print(f\"  Items remaining: {len(os.listdir())}\")\n",
        "\n",
        "finally:\n",
        "    # Always return to original directory\n",
        "\n",
        "    os.chdir(cwd)\n",
        "\n",
        "    # Remove the demo directory if empty\n",
        "\n",
        "    try:\n",
        "        test_dir.rmdir()\n",
        "        print(\"Demo directory removed\")\n",
        "    except OSError as e:\n",
        "        print(f\"Could not remove demo directory: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Hr8du2k56s"
      },
      "source": [
        "## Listing and querying file information\n",
        "\n",
        "The `os.scandir()` function can be used to query more detailed information on the a file or directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSP78KjBk56t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321f90ff-d4e9-4670-fb78-503a0b9324d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------\n",
            "name .config\n",
            "path ./.config\n",
            "is_dir True\n",
            "is_file False\n",
            "------------------------\n",
            "name testfile\n",
            "path ./testfile\n",
            "is_dir False\n",
            "is_file True\n",
            "------------------------\n",
            "name sample_data\n",
            "path ./sample_data\n",
            "is_dir True\n",
            "is_file False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "with os.scandir() as items:\n",
        "    for entry in items:\n",
        "        print(\"------------------------\")\n",
        "        print(\"name\", entry.name)\n",
        "        print(\"path\", entry.path)\n",
        "        print(\"is_dir\", entry.is_dir())\n",
        "        print(\"is_file\", entry.is_file())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMFpNgc4k56y"
      },
      "source": [
        "## Walking directories with os.walk()\n",
        "\n",
        "The `os.walk()` function enables you to traverse directories as an iteration using the for-statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDVZkfB-k560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba63e57-4a4f-446a-a0f6-c86d90bf5ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--->\n",
            ".\n",
            "['.config', 'sample_data']\n",
            "['testfile']\n",
            "<---\n",
            "--->\n",
            "./.config\n",
            "['configurations', 'logs']\n",
            "['hidden_gcloud_config_universe_descriptor_data_cache_configs.db', '.last_opt_in_prompt.yaml', '.last_survey_prompt.yaml', 'active_config', 'default_configs.db', '.last_update_check.json', 'gce', 'config_sentinel']\n",
            "<---\n",
            "--->\n",
            "./.config/configurations\n",
            "[]\n",
            "['config_default']\n",
            "<---\n",
            "--->\n",
            "./.config/logs\n",
            "['2025.08.18']\n",
            "[]\n",
            "<---\n",
            "--->\n",
            "./.config/logs/2025.08.18\n",
            "[]\n",
            "['13.38.17.023788.log', '13.38.07.073430.log', '13.38.15.728895.log', '13.37.46.544538.log', '13.38.25.411240.log', '13.38.26.129653.log']\n",
            "<---\n",
            "--->\n",
            "./sample_data\n",
            "[]\n",
            "['README.md', 'anscombe.json', 'mnist_train_small.csv', 'mnist_test.csv', 'california_housing_test.csv', 'california_housing_train.csv']\n",
            "<---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    print(\"--->\")\n",
        "    print(root)\n",
        "    print(dirs)\n",
        "    print(files)\n",
        "    print(\"<---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16u6Vtmzk566"
      },
      "source": [
        "## Querying file information\n",
        "\n",
        "On Unix-based platform the `os.stat()` function can return detailed information on files and directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fBG_b4kk567"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "with open(\"testfile\", \"w\") as f:\n",
        "    f.write(\"testfile\")\n",
        "\n",
        "os.mkdir(\"testdir2\")\n",
        "\n",
        "statinfo_file = os.stat(\"testfile\")\n",
        "statinfo_dir = os.stat(\"testdir2\")\n",
        "\n",
        "print(statinfo_file)\n",
        "print(statinfo_dir)\n",
        "print(statinfo_file.st_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4xHhx2tk57A"
      },
      "source": [
        "## Path information\n",
        "\n",
        "The os.path module contains even more functions for querying path and file information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autiiqIBk57C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55668df7-e2db-460d-e6c0-17356c709ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "test.txt\n",
            "/home/user\n",
            "test.txt is not valid\n",
            "/root\n",
            "1755673347.2420638\n",
            "1755673347.243064\n",
            "1755673347.243064\n",
            "8\n",
            "No absolute path\n",
            "No absolute path\n",
            "ospath1.py is a file\n",
            "ospath1.py is not a directory\n",
            "c:\\Users\\jonas/test.txt\n",
            "('c:\\\\Users\\\\jonas', 'test.txt')\n",
            "c:\\Users\\jonas\n",
            "test.txt\n",
            "('', 'c:\\\\Users\\\\jonas/test.txt')\n",
            "('c:\\\\Users\\\\jonas/test', '.txt')\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.path.abspath('.')) # Expands relative path to absolute\n",
        "print(os.path.basename('/home/user/test.txt')) # Filename part of filename\n",
        "print(os.path.dirname('/home/user/test.txt'))  # Directory part of filename\n",
        "\n",
        "# Create a test file\n",
        "\n",
        "with open(\"testfile_path\", \"w\") as f:\n",
        "    f.write(\"testfile\")\n",
        "\n",
        "# Check if file exists\n",
        "\n",
        "if os.path.exists('/home/user/test.txt'):\n",
        "    print('test.txt is valid')\n",
        "else:\n",
        "    print('test.txt is not valid')\n",
        "\n",
        "# Expand user directory ~ (tilde)\n",
        "\n",
        "print(os.path.expanduser('~'))\n",
        "\n",
        "# Query file meta data\n",
        "\n",
        "print(os.path.getatime('testfile_path')) # Access time\n",
        "print(os.path.getmtime('testfile_path')) # Modification time\n",
        "print(os.path.getctime('testfile_path')) # Creation time\n",
        "print(os.path.getsize('testfile_path'))  # Size of file\n",
        "\n",
        "# Check if a path is absolute or not\n",
        "\n",
        "if os.path.isabs('testfile_path'):\n",
        "    print('Absolute path')\n",
        "else:\n",
        "    print('No absolute path')\n",
        "\n",
        "if os.path.isabs(\"C:/Users/jonas/Development/python_book/examples/rtl/ospath1.py\"):\n",
        "    print('Absolute path')\n",
        "else:\n",
        "    print('No absolute path')\n",
        "\n",
        "# Check if a path is a file\n",
        "\n",
        "if os.path.isfile('testfile_path'):\n",
        "    print('ospath1.py is a file')\n",
        "else:\n",
        "    print('ospath1.py is not a file')\n",
        "\n",
        "# Check if a path is directory\n",
        "\n",
        "if os.path.isdir('testfile_path'):\n",
        "    print('ospath1.py is a directory')\n",
        "else:\n",
        "    print('ospath1.py is not a directory')\n",
        "\n",
        "# Combining directory and filename in a platform neutran way\n",
        "\n",
        "dir_name = 'c:\\\\Users\\\\jonas'\n",
        "file_name = 'test.txt'\n",
        "\n",
        "file_path = os.path.join(dir_name, file_name)\n",
        "print(file_path)\n",
        "\n",
        "# Use os.path.split() to split a path in a platform neutral way\n",
        "\n",
        "print(os.path.split(file_path))\n",
        "dir_name, file_name = os.path.split(file_path)\n",
        "print(dir_name)\n",
        "print(file_name)\n",
        "\n",
        "# Extract drive letter if exists (Windows only)\n",
        "\n",
        "print(os.path.splitdrive(file_path))\n",
        "\n",
        "# Extract file extension\n",
        "\n",
        "print(os.path.splitext(file_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujj6QCEak57F"
      },
      "source": [
        "## Path management using pathlib\n",
        "\n",
        "pathlib is a module implementing OO-based file and path management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0UZgHozk57G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e195d7f4-4bed-4f6b-fe08-c2bac20745dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = /contents\n",
            "p after append /contents/testfile\n",
            "p.exists() returns False\n",
            "q after p.resolve() /contents/testfile\n",
            "q.parts = ('/', 'contents', 'testfile')\n",
            "q.drive = \n",
            "r = pl.Path.cwd() => /content\n",
            "r.exists() True\n",
            "r.is_dir() True\n",
            "r.is_file() False\n",
            "s = sl.Path.home() => /root\n"
          ]
        }
      ],
      "source": [
        "import pathlib as pl\n",
        "\n",
        "# Create a path object\n",
        "\n",
        "p = pl.Path('/contents')\n",
        "\n",
        "print(\"p =\",p)\n",
        "\n",
        "# Appending a file/directory to a path using the / operator\n",
        "\n",
        "p = p / \"testfile\"\n",
        "print(\"p after append\", p)\n",
        "\n",
        "# Check if a path object exists in the file system\n",
        "\n",
        "print(\"p.exists() returns\", p.exists())\n",
        "\n",
        "# Make path absolute\n",
        "\n",
        "q = p.resolve()\n",
        "print(\"q after p.resolve()\", q)\n",
        "\n",
        "# Extract parts of path\n",
        "\n",
        "print(\"q.parts =\", q.parts)\n",
        "print(\"q.drive =\", q.drive)  # Windows only\n",
        "\n",
        "# Create a path for current working directory\n",
        "\n",
        "r = pl.Path.cwd()\n",
        "print(\"r = pl.Path.cwd() =>\", r)\n",
        "\n",
        "print(\"r.exists()\", r.exists())\n",
        "print(\"r.is_dir()\", r.is_dir())\n",
        "print(\"r.is_file()\", r.is_file())\n",
        "\n",
        "# Get a path object representing the home dir\n",
        "\n",
        "s = pl.Path.home()\n",
        "print(\"s = sl.Path.home() =>\", s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r42g0I1Qk57M"
      },
      "source": [
        "## Iterating with pathlib\n",
        "\n",
        "One really nice thing with Path object is that you can iterate over them using the `.iterdir()` method. In the example we iterate through the directory and check if objects are files or direcrtories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-1sZQL2k57P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d672f5-f1f1-4d4e-f7b1-b5543fceb74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config - katalog\n",
            "testfile - fil\n",
            "testfile_path - fil\n",
            "sample_data - katalog\n"
          ]
        }
      ],
      "source": [
        "import pathlib as pl\n",
        "\n",
        "p = pl.Path(\".\")\n",
        "\n",
        "for x in p.iterdir():\n",
        "    if x.is_dir():\n",
        "        print(x,'- katalog')\n",
        "    else:\n",
        "        print(x,'- fil')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUXxwg5Fk57U"
      },
      "source": [
        "## Changing current path with pathlib\n",
        "\n",
        "The objects in pathlib doesn't change the actual working directory. To do this you need to call a system function such as `os.chdir(p)`, where p is a Path-object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp6q29C7k57V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1bbad4-cb61-4813-b219-6df4d8664c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = ..\n",
            "p.resolve() =  /\n",
            "pl.Path.cwd() = /\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib as pl\n",
        "\n",
        "# Get the path of the directory above the current dir\n",
        "\n",
        "p = pl.Path('..')\n",
        "print(\"p =\", p)\n",
        "print(\"p.resolve() = \", p.resolve())\n",
        "\n",
        "# Change to this directory\n",
        "\n",
        "os.chdir(p)\n",
        "\n",
        "# Get the current working dir using the .cwd() method\n",
        "\n",
        "q = pl.Path.cwd()\n",
        "print(\"pl.Path.cwd() =\", q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig9LvYxMk57Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ea6bc9-e0a6-491c-f78b-14a3a432e63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_path = /\n",
            "old_path = /root\n",
            "pl.Path.cwd() => /\n",
            "(pl.Path.cwd() => (afte chdir to old_path) /root\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib as pl\n",
        "\n",
        "# Make sure we are in our home dir\n",
        "\n",
        "os.chdir(os.path.expanduser('~'))\n",
        "\n",
        "new_path = pl.Path('..')\n",
        "old_path = pl.Path.cwd()\n",
        "\n",
        "print(\"new_path =\", new_path.resolve())\n",
        "print(\"old_path =\", old_path)\n",
        "\n",
        "os.chdir(new_path)\n",
        "\n",
        "print(\"pl.Path.cwd() =>\", pl.Path.cwd())\n",
        "\n",
        "os.chdir(old_path)\n",
        "\n",
        "print(\"(pl.Path.cwd() => (after chdir to old_path)\", old_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd0Ju_91k57e"
      },
      "source": [
        "## Temporary files\n",
        "\n",
        "In many applications you need to create temporary files that are required when running, but doesn't need to be stored afterwards. In Python there are several functions for securely creating temporary files."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using mkstemp\n",
        "\n",
        "The `mkstemp(...)` function in the `tempfile` module securely creates a temporary file in system designated place for temporary files. It will return a file descriptor (fd) and the full path to the file. You can write directly to this file, however in most cases it is more convenient to create a Python file object using the `os.fdopen(...)` method, see the code below. Please note that the temporary file is not automatically removed after use. In the code below we remove the file in the `finally` section."
      ],
      "metadata": {
        "id": "CjnpD4UBY8or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD9ZYJwOk57f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a775227c-51df-4bd4-9a8c-6067148cd1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Method 1: Using mkstemp ===\n",
            "Temporary file created: /tmp/python_demo_e6nkfkbf.txt\n",
            "File exists: True\n",
            "File permissions: 600\n",
            "File content:\n",
            "This is written to the temporary file\n",
            "Line 2 of content\n",
            "\n",
            "Temporary file cleaned up: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Method 1: Using mkstemp (lower-level, more control)\n",
        "\n",
        "print(\"=== Method 1: Using mkstemp ===\")\n",
        "temp_fd, temp_path = tempfile.mkstemp(suffix='.txt', prefix='python_demo_')\n",
        "\n",
        "try:\n",
        "    print(f'Temporary file created: {temp_path}')\n",
        "    print(f'File exists: {os.path.isfile(temp_path)}')\n",
        "    print(f'File permissions: {oct(os.stat(temp_path).st_mode)[-3:]}')\n",
        "\n",
        "    # Write to the temporary file using the file descriptor\n",
        "\n",
        "    with os.fdopen(temp_fd, 'w+t') as temp_file:\n",
        "        temp_file.write('This is written to the temporary file\\n')\n",
        "        temp_file.write('Line 2 of content\\n')\n",
        "\n",
        "        # Read back the content\n",
        "\n",
        "        temp_file.seek(0)\n",
        "        content = temp_file.read()\n",
        "        print(f'File content:\\n{content}')\n",
        "\n",
        "finally:\n",
        "    # Important: Always clean up temporary files\n",
        "    if os.path.exists(temp_path):\n",
        "        os.remove(temp_path)\n",
        "        print(f'Temporary file cleaned up: {not os.path.exists(temp_path)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using TemporaryFile class (recommended)\n",
        "\n",
        "A more automatic and easy to use method to create temporary files in Python is to use the `TemporaryFile` class in `tempfile`. When you instance this class is creates a temporary file object which you can use like any file object in Python. When the variable goes out of scope it will automatically delete the temporary file. The best way of using the class is in a `with`-statement as shown in the example below:\n"
      ],
      "metadata": {
        "id": "ZHwR1M_hZPpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Method 2: Using TemporaryFile (recommended) ===\")\n",
        "# Method 2: Using TemporaryFile (automatically cleaned up)\n",
        "with tempfile.TemporaryFile(mode='w+t', suffix='.txt') as temp_file:\n",
        "    temp_file.write('This content will be automatically cleaned up\\n')\n",
        "    temp_file.write('No manual cleanup required!\\n')\n",
        "\n",
        "    # Read back\n",
        "    temp_file.seek(0)\n",
        "    content = temp_file.read()\n",
        "    print(f'Content: {content.strip()}')\n",
        "\n",
        "    # File is automatically deleted when exiting the with block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0abdpOK6ZF2h",
        "outputId": "b8b50957-6714-43df-966b-7e5b671cbb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Method 2: Using TemporaryFile (recommended) ===\n",
            "Content: This content will be automatically cleaned up\n",
            "No manual cleanup required!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using NamedTemporaryFile class\n",
        "\n",
        "If you need to know the actual name of the temporary class and you still want the benefits of the `TemporaryFile`-class you can instead use the `NamedTemporaryFile`-class, which provides your with a named file using the `.name` property. See example below:"
      ],
      "metadata": {
        "id": "Nt5uN5JyZd9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Method 3: Using NamedTemporaryFile ===\")\n",
        "# Method 3: NamedTemporaryFile (has a name but still auto-cleaned)\n",
        "with tempfile.NamedTemporaryFile(mode='w+t', suffix='.txt', delete=True) as temp_file:\n",
        "    print(f'Named temporary file: {temp_file.name}')\n",
        "    temp_file.write('Named temporary file content\\n')\n",
        "    temp_file.flush()  # Ensure content is written\n",
        "\n",
        "    # You can access the file by name while it's open\n",
        "    print(f'File size: {Path(temp_file.name).stat().st_size} bytes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WozbfCq-ZKOc",
        "outputId": "986791c0-a515-4293-d8cb-e6d5298e72e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Method 3: Using NamedTemporaryFile ===\n",
            "Named temporary file: /tmp/tmpnrs3jo6n.txt\n",
            "File size: 29 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using TemporaryDirectory class\n",
        "\n",
        "In some cases your application will need to be able to create files in a temporary directory. This can be done using the `TemporaryDirectory`-class. This class creatas a temporary diretory, which removed all content and directory when it is not needed anymore. Just like the previous tempfile classes it is always a good idea to use them in a `with`-statement."
      ],
      "metadata": {
        "id": "D7rncw5xZj8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Temporary Directory ===\")\n",
        "# Bonus: Temporary directories\n",
        "with tempfile.TemporaryDirectory(prefix='python_demo_') as temp_dir:\n",
        "    print(f'Temporary directory: {temp_dir}')\n",
        "\n",
        "    # Create files in the temporary directory\n",
        "    temp_file_path = Path(temp_dir) / 'example.txt'\n",
        "    temp_file_path.write_text('File in temporary directory')\n",
        "\n",
        "    print(f'Files in temp dir: {list(Path(temp_dir).iterdir())}')\n",
        "    # Directory and all contents automatically cleaned up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTYu_5BEZL3t",
        "outputId": "26811815-0b4c-4cd1-b5d4-a026745ab8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Temporary Directory ===\n",
            "Temporary directory: /tmp/python_demo_6is_b1t7\n",
            "Files in temp dir: [PosixPath('/tmp/python_demo_6is_b1t7/example.txt')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iG2tOqZk57n"
      },
      "source": [
        "---\n",
        "# Process management (subprocess)\n",
        "\n",
        "One big usage of Python is as a workflow or glue language for running and controling other applications. To be able to do this we need tools for starting applications and querying status and output from these. In the following chapter we will go through some of the function that exists in Python for this purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFALBpiok57o"
      },
      "source": [
        "## Using the subprocess.run()\n",
        "\n",
        "`subprocess.run()` is the recommended way of running another application. The run function takes several arguments typically\n",
        "\n",
        "* **cmd** - Path or command that should be run\n",
        "* **shell** - Does the command required a shell to be run (True). Can be a security risk so beware.\n",
        "* **capture_outpout** - output is stored int the return value as stdout or stderr.\n",
        "* **text** - If set to True it will return string instead of bytes in the outpout.\n",
        "* **timeout** - Time limit to wait for the external process to run.\n",
        "\n",
        "When the process terminates the return status is returned in the attribute `returncode`.\n",
        "\n",
        "The command can also generate exceptions such as `TimeoutExpired`, triggered at the tiemout time and `SubprocessError` when there was an error starting the process. The example below shows the usage of the `run()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX1lQm9dk57r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7712ec6f-6191-4974-9665-22acc5e617f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: Linux\n",
            "Command: ls -la\n",
            "Return code: 0\n",
            "✅ Process completed successfully\n",
            "Output:\n",
            "total 72\n",
            "drwx------ 1 root root 4096 Aug 20 06:57 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 20 06:56 ..\n",
            "-r-xr-xr-x 1 root root 1071 Jan  1  2000 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .cache\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .config\n",
            "drwxr-xr-x 5 root root 4096 Aug 18 13:52 .ipython\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .julia\n",
            "drwx------ 1 root root 4096 Aug 18 13:52 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Aug 20 06:57 .keras\n",
            "drwx------ 3 root root 4096 Aug 18 13:15 .launchpadlib\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .local\n",
            "drwxr-xr-x 4 root root 4096 Aug 18 13:52 .npm\n",
            "-rw-r--r-- 1 root root  161 Jul  9  2019 .profile\n",
            "-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n",
            "-rw-r--r-- 1 root root  211 Aug 18 13:52 .wget-hsts\n",
            "\n",
            "\n",
            "==================================================\n",
            "Running Python version check:\n",
            "✅ Python 3.12.11\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "# Cross-platform directory listing command\n",
        "\n",
        "if platform.system() == \"Windows\":\n",
        "    cmd = ['dir']\n",
        "    shell_needed = True\n",
        "else:\n",
        "    cmd = ['ls', '-la']\n",
        "    shell_needed = False\n",
        "\n",
        "print(f\"Running on: {platform.system()}\")\n",
        "print(f\"Command: {' '.join(cmd) if not shell_needed else cmd[0]}\")\n",
        "\n",
        "try:\n",
        "\n",
        "    # Using subprocess.run() - the recommended modern approach\n",
        "\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        shell=shell_needed,\n",
        "        capture_output=True,  # Capture both stdout and stderr\n",
        "        text=True,            # Return strings instead of bytes\n",
        "        timeout=10            # Prevent hanging\n",
        "    )\n",
        "\n",
        "    print(f\"Return code: {result.returncode}\")\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(\"✅ Process completed successfully\")\n",
        "        print(f\"Output:\\n{result.stdout}\")\n",
        "    else:\n",
        "        print(\"❌ Process failed\")\n",
        "        print(f\"Error output:\\n{result.stderr}\")\n",
        "\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"❌ Process timed out\")\n",
        "except subprocess.SubprocessError as e:\n",
        "    print(f\"❌ Subprocess error: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Unexpected error: {e}\")\n",
        "\n",
        "# Demonstrate with Python command (cross-platform)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running Python version check:\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, '--version'], # Python interpreter executable\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=5\n",
        "    )\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"✅ {result.stdout.strip()}\")\n",
        "    else:\n",
        "        print(f\"❌ Failed: {result.stderr}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error checking Python version: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Popen with .wait()"
      ],
      "metadata": {
        "id": "_i0sNvQIh6rf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5bAo28Pk57z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102e29b6-cd0d-4910-c4e9-bae59eb83f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processen returnerade 0\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "p = subprocess.Popen(['ls', '-la'])\n",
        "\n",
        "# Other processing here...\n",
        "\n",
        "# Wait for process to complete\n",
        "\n",
        "p.wait()\n",
        "\n",
        "if p.returncode == 0:\n",
        "    print('Processen returnerade 0')\n",
        "else:\n",
        "    print('Processen returnerade felkoden = ', p.returncode)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Popen with .poll()"
      ],
      "metadata": {
        "id": "toMP9En5iR9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6x0QlC3k573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52031bcd-4a80-4bd4-f499-87518b664d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Processen returnerade 0\n"
          ]
        }
      ],
      "source": [
        "import subprocess, time\n",
        "\n",
        "p = subprocess.Popen(['sleep', '5'])\n",
        "\n",
        "while p.poll() is None:\n",
        "    print('Väntar...')\n",
        "    time.sleep(1)\n",
        "\n",
        "if p.returncode == 0:\n",
        "    print('Processen returnerade 0')\n",
        "else:\n",
        "    print('Processen returnerade felkoden = ', p.returncode)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Popen with polling and .communicate()"
      ],
      "metadata": {
        "id": "His4MXvwicbw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK6nTacsk577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f127b8-f6fe-46f8-eb91-86808c9f0e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Väntar...\n",
            "Processen returnerade 0\n",
            "standard output:\n",
            "total 72\n",
            "drwx------ 1 root root 4096 Aug 20 06:57 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 20 06:56 ..\n",
            "-r-xr-xr-x 1 root root 1071 Jan  1  2000 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .cache\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .config\n",
            "drwxr-xr-x 5 root root 4096 Aug 18 13:52 .ipython\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .julia\n",
            "drwx------ 1 root root 4096 Aug 18 13:52 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Aug 20 06:57 .keras\n",
            "drwx------ 3 root root 4096 Aug 18 13:15 .launchpadlib\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .local\n",
            "drwxr-xr-x 4 root root 4096 Aug 18 13:52 .npm\n",
            "-rw-r--r-- 1 root root  161 Jul  9  2019 .profile\n",
            "-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n",
            "-rw-r--r-- 1 root root  211 Aug 18 13:52 .wget-hsts\n",
            "\n",
            "standard error:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess, time\n",
        "\n",
        "p = subprocess.Popen('ls -la; sleep 4', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
        "\n",
        "while p.poll() is None:\n",
        "    print('Väntar...')\n",
        "    time.sleep(1)\n",
        "\n",
        "stdout, stderr = p.communicate()\n",
        "\n",
        "if p.returncode == 0:\n",
        "    print('Processen returnerade 0')\n",
        "    print('standard output:')\n",
        "    print(stdout)\n",
        "    print('standard error:')\n",
        "    print(stderr)\n",
        "else:\n",
        "    print('Processen returnerade felkoden = ', p.returncode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4wGVh7ck579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836195f8-d336-458d-a48e-6c1aa470a9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processen returnerade 0\n",
            "standard output:\n",
            "total 72\n",
            "drwx------ 1 root root 4096 Aug 20 06:57 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 20 06:56 ..\n",
            "-r-xr-xr-x 1 root root 1071 Jan  1  2000 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .cache\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:53 .config\n",
            "drwxr-xr-x 5 root root 4096 Aug 18 13:52 .ipython\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .julia\n",
            "drwx------ 1 root root 4096 Aug 18 13:52 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Aug 20 06:57 .keras\n",
            "drwx------ 3 root root 4096 Aug 18 13:15 .launchpadlib\n",
            "drwxr-xr-x 1 root root 4096 Aug 18 13:24 .local\n",
            "drwxr-xr-x 4 root root 4096 Aug 18 13:52 .npm\n",
            "-rw-r--r-- 1 root root  161 Jul  9  2019 .profile\n",
            "-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n",
            "-rw-r--r-- 1 root root  211 Aug 18 13:52 .wget-hsts\n",
            "\n",
            "standard error:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "with subprocess.Popen('ls -la', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) as p:\n",
        "    stdout, stderr = p.communicate()\n",
        "\n",
        "    if p.returncode == 0:\n",
        "        print('Processen returnerade 0')\n",
        "        print('standard output:')\n",
        "        print(stdout)\n",
        "        print('standard error:')\n",
        "        print(stderr)\n",
        "    else:\n",
        "        print('Processen returnerade felkoden = ', p.returncode)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping process management in function"
      ],
      "metadata": {
        "id": "aYwGEL9kitKi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLRZk2Spk58C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a74fcb-af37-4d61-e4c9-8fd7bbe16a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">total 72\n",
            ">drwx------ 1 root root 4096 Aug 20 06:57 .\n",
            ">drwxr-xr-x 1 root root 4096 Aug 20 06:56 ..\n",
            ">-r-xr-xr-x 1 root root 1071 Jan  1  2000 .bashrc\n",
            ">drwxr-xr-x 1 root root 4096 Aug 18 13:53 .cache\n",
            ">drwxr-xr-x 1 root root 4096 Aug 18 13:53 .config\n",
            ">drwxr-xr-x 5 root root 4096 Aug 18 13:52 .ipython\n",
            ">drwxr-xr-x 1 root root 4096 Aug 18 13:24 .julia\n",
            ">drwx------ 1 root root 4096 Aug 18 13:52 .jupyter\n",
            ">drwxr-xr-x 2 root root 4096 Aug 20 06:57 .keras\n",
            ">drwx------ 3 root root 4096 Aug 18 13:15 .launchpadlib\n",
            ">drwxr-xr-x 1 root root 4096 Aug 18 13:24 .local\n",
            ">drwxr-xr-x 4 root root 4096 Aug 18 13:52 .npm\n",
            ">-rw-r--r-- 1 root root  161 Jul  9  2019 .profile\n",
            ">-r-xr-xr-x 1 root root  254 Jan  1  2000 .tmux.conf\n",
            ">-rw-r--r-- 1 root root  211 Aug 18 13:52 .wget-hsts\n",
            ">\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "\n",
        "def execute_with_output(cmd):\n",
        "\n",
        "    with subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, universal_newlines=True) as p:\n",
        "        stdout, _ = p.communicate()\n",
        "\n",
        "        if p.returncode == 0:\n",
        "            return stdout\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    output = execute_with_output('ls -la')\n",
        "\n",
        "    if output is not None:\n",
        "\n",
        "        lines = output.split(\"\\n\")\n",
        "\n",
        "        for line in lines:\n",
        "            print('>' + line)\n",
        "    else:\n",
        "        print('Ingen utdata returnerades.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-M4LOnk58G"
      },
      "source": [
        "---\n",
        "# Logging\n",
        "\n",
        "For larger applications there is often a need to create log entries in a more structured way. The `print()`-statement is not suitable for this. The `logging` module in Python implements this functionality. The module provides the functions `info()` for logging informational messages, `warning()` for logging warning messages on unusual states in your application, `error()` for logging any errors occuring in your application. There is also a `debug()` functions for logging things for finding problems in your application. Usually debugging messasges are not activated by default.\n",
        "\n",
        "What is displayed in the log can be controlled by using the `setLevel()` method on the logger as shown below:\n",
        "\n",
        "    logging.getLogger().setLevel(logging.INFO)\n",
        "\n",
        "Setting the level to `INFO` will display all log messages including `INFO`. That is `INFO`, `WARNING`, `ERROR`. Setting it to `ERROR` will only at this level. The `DEBUG` level is higher than.\n",
        "\n",
        "It is also possible to customise the logging output by changing the logformat. This is also illustrated in the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh42Byxok58G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b17290-f6db-4bc9-9307-2cfa189d5930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logging with different levels ===\n",
            "\n",
            "1. INFO level and above:\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | 🚀 Application starting...\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | Processing user: alice\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | Processing user: bob\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | Processing user: charlie\n",
            "2025-08-20 11:37:36 | WARNING  | MyApplication | ⚠️  User charlie has incomplete profile\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | ✅ All users processed successfully\n",
            "2025-08-20 11:37:36 | INFO     | MyApplication | 🏁 Application workflow completed\n",
            "\n",
            "2. WARNING level and above:\n",
            "2025-08-20 11:37:36 | WARNING  | MyApplication | ⚠️  User charlie has incomplete profile\n",
            "\n",
            "3. ERROR level only:\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "# --- This is the normal logging setup\n",
        "\n",
        "# Configure logging with a better format\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "\n",
        "# --- BELOW is required for Colab/Notebooks ----\n",
        "\n",
        "# Remove any handlers that Jupyter/Colab already set up\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "# Now configure logging as you want\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "\n",
        "def simulate_application_workflow():\n",
        "    \"\"\"Simulate a real application with different logging scenarios\"\"\"\n",
        "    logger = logging.getLogger('MyApplication')\n",
        "\n",
        "    logger.info(\"🚀 Application starting...\")\n",
        "\n",
        "    # Simulate processing some data\n",
        "    try:\n",
        "        logger.debug(\"Processing user data...\")\n",
        "\n",
        "        # Simulate different scenarios\n",
        "        users = ['alice', 'bob', 'charlie']\n",
        "\n",
        "        for user in users:\n",
        "            logger.info(f\"Processing user: {user}\")\n",
        "\n",
        "            if user == 'charlie':\n",
        "                logger.warning(f\"⚠️  User {user} has incomplete profile\")\n",
        "\n",
        "        logger.info(\"✅ All users processed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Error processing users: {e}\")\n",
        "        logger.exception(\"Full traceback:\")  # This includes the stack trace\n",
        "\n",
        "    logger.info(\"🏁 Application workflow completed\")\n",
        "\n",
        "print(\"=== Logging with different levels ===\")\n",
        "\n",
        "# Test different logging levels\n",
        "print(\"\\n1. INFO level and above:\")\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "simulate_application_workflow()\n",
        "\n",
        "print(\"\\n2. WARNING level and above:\")\n",
        "logging.getLogger().setLevel(logging.WARNING)\n",
        "simulate_application_workflow()\n",
        "\n",
        "print(\"\\n3. ERROR level only:\")\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "simulate_application_workflow()\n",
        "\n",
        "# Reset to INFO for subsequent examples\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii_e2absvWzM"
      },
      "source": [
        "---\n",
        "# Data serialization and deserialization\n",
        "\n",
        "Most applications need to be able to store variables to disk. The easiest way is to use the Python `open()` function to create a file and write to it. However in this case you need to define the structure of your data yourself and define your own file format. In Python there are better ways of reading and writing data to and from disk using the built-in serialisation and deserialisation libraries Pickle and JSON. These functions know how to store the standard Python data structures and read them back again. In the following sections we will go through how you use these functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmJtoOZTvWzN"
      },
      "source": [
        "## Storing variables and data structures using Pickle\n",
        "\n",
        "Pickle is the default mechanism for storing Python data structures to disk. To use Pickle we import the pickle module."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "yxmgnIVcUzkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To pickle a datastructure to disk we use the `dump()` function. This function takes the data you want to write and a filename of the file to store your data in as input. In the example below we write our dictionary, `my_data` to the file `mydata.pkl`."
      ],
      "metadata": {
        "id": "L5_0tgGaU2Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = {\"a number\": 42, \"a list\": list(range(1000)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "with open(\"mydata.pkl\", \"wb\") as my_file:\n",
        "    pickle.dump(my_data, my_file)"
      ],
      "metadata": {
        "id": "kJ4aVBEjVCPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pickle-files stores the Python data structures in a compact binary non-readable form.\n",
        "\n",
        "We can read the files back using the `load()` method."
      ],
      "metadata": {
        "id": "IkaqgeR5Veht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('mydata.pkl', 'rb') as my_file:\n",
        "    my_data_copy = pickle.load(my_file)\n",
        "\n",
        "print(my_data_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsxj9RdGVyQc",
        "outputId": "06f461a9-7200-4155-c099-7f57d75e0816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a number': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], 'a dict': {'a': 1, 'b': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see we read the file again into a new data structure which contains the exact data as in `my_data`."
      ],
      "metadata": {
        "id": "rsGSO-tJWhFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is also possible to write multiple data structures using mutiple calls of `dump()`."
      ],
      "metadata": {
        "id": "eQvIlEd2XEYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "section_1 = {\"A\": 42, \"a list\": list(range(1000)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "section_2 = {\"B\": 84, \"a list\": list(range(1000)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "with open(\"sections.pkl\", \"wb\") as my_file:\n",
        "    pickle.dump(section_1, my_file)\n",
        "    pickle.dump(section_2, my_file)"
      ],
      "metadata": {
        "id": "L5eczagfXVw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is however important that the data is read back in the same order as it was written."
      ],
      "metadata": {
        "id": "IQutzqe4XuGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sections.pkl', 'rb') as my_file:\n",
        "    section_1_copy = pickle.load(my_file)\n",
        "    section_2_copy = pickle.load(my_file)\n",
        "\n",
        "print(section_1_copy)\n",
        "print(section_2_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy9FpPmpX1jw",
        "outputId": "782fa191-b591-460e-b5ec-205a2a006d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], 'a dict': {'a': 1, 'b': 2}}\n",
            "{'B': 84, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], 'a dict': {'a': 1, 'b': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data can also be serialised to strings or streams. This can be useful if you want to serialise over a network connection or similar connection. In this case you call the `dumps()` function which converts the data structures to a string that then can be transferred over a network connection.\n",
        "\n",
        "In the example below we pickle our data structure to a string which we then compress and decompress using the `zlib` module. This is a good module if you want to compress your pickle data before writing to disk."
      ],
      "metadata": {
        "id": "5-JqwPmPX8rV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FuSl7wuvWzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cb436e-383b-462e-b14b-ef03d974b1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a number': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], 'a dict': {'a': 1, 'b': 2}}\n",
            "Uncompressed length: 2811 bytes\n",
            "Compressed length: 1915 bytes\n",
            "Ratio: 1.47\n"
          ]
        }
      ],
      "source": [
        "import pickle, zlib\n",
        "\n",
        "my_data = {\"a number\": 42, \"a list\": list(range(1000)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "# Dump data structure to a string\n",
        "\n",
        "my_data_dump = pickle.dumps(my_data)\n",
        "uncompressed_length = len(my_data_dump)\n",
        "\n",
        "# Compress data using zlib\n",
        "\n",
        "my_data_compressed = zlib.compress(my_data_dump)\n",
        "compressed_length = len(my_data_compressed)\n",
        "\n",
        "# Uncompress data again\n",
        "\n",
        "my_data_uncompressed = zlib.decompress(my_data_compressed)\n",
        "\n",
        "# Convert uncompressed string to a Python data structure again\n",
        "\n",
        "my_data_copy = pickle.loads(my_data_uncompressed)\n",
        "print(my_data_copy)\n",
        "\n",
        "print(f\"Uncompressed length: {uncompressed_length} bytes\")\n",
        "print(f\"Compressed length: {compressed_length} bytes\")\n",
        "print('Ratio:', round(uncompressed_length / compressed_length, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwibnSOSvWzN"
      },
      "source": [
        "## Storing variables and data structures in JSON\n",
        "\n",
        "Python has built in functions for writing data types to disk. If readability is important the Javascript Object Notation or JSON can be used as a storage format. In Python this functionality is found in the **json**-module. The module is very similar to the pickle module and has similar functions.\n",
        "\n",
        "To use json we first import the module:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "gmh4P_DWZ2bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To write our data in JSON-format to disk we use the `dump()` function in the same way as for pickle."
      ],
      "metadata": {
        "id": "fChiRPp_Z61E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = {\"a number\": 42, \"a list\": list(range(1000)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "with open(\"mydata.json\", \"w\") as my_file:\n",
        "    json.dump(my_data, my_file)"
      ],
      "metadata": {
        "id": "e8DwGVrkfFzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between pickle and json is that JSON is human readable. Looking at the generated file we get:"
      ],
      "metadata": {
        "id": "5h7CayQOfUZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mydata.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4HRrdZGfda0",
        "outputId": "43354a95-a657-4fb0-85a3-49cc9ee4ad0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"a number\": 42, \"a list\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], \"a dict\": {\"a\": 1, \"b\": 2}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see here that the JSON file format is very close to how our Python data structures are defined i our Python source files. We can make the json output a little more readable by adding some additional parameters in the `dump()` function:"
      ],
      "metadata": {
        "id": "Qi2qVlGnfhSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = {\"a number\": 42, \"a list\": list(range(10)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "with open(\"mydata_formatted.json\", \"w\") as my_file:\n",
        "    json.dump(my_data, my_file, sort_keys=True, indent=4)"
      ],
      "metadata": {
        "id": "eVmIK4BygHM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which looks like this:"
      ],
      "metadata": {
        "id": "9PIh6CLugR11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mydata_formatted.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izng5_9vgVS_",
        "outputId": "3a2d7bb4-2520-4341-b918-f2456f012b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"a dict\": {\n",
            "        \"a\": 1,\n",
            "        \"b\": 2\n",
            "    },\n",
            "    \"a list\": [\n",
            "        0,\n",
            "        1,\n",
            "        2,\n",
            "        3,\n",
            "        4,\n",
            "        5,\n",
            "        6,\n",
            "        7,\n",
            "        8,\n",
            "        9\n",
            "    ],\n",
            "    \"a number\": 42\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading json files is done in similar way as with pickle using the `load()` function."
      ],
      "metadata": {
        "id": "8mhEHdU7g0vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('mydata.json', 'r') as my_file:\n",
        "    my_data_copy = json.load(my_file)\n",
        "\n",
        "print(my_data_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S54PCXDNhCdj",
        "outputId": "cbea517e-0e1c-4c5c-cdd4-ddcdc4e31849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a number': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999], 'a dict': {'a': 1, 'b': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We usually don't write multiple times when use the json module as the structure of json must be representable as data structure in Python. If you want to store multiple structures in a JSON file either store them in an outer list or dictionary like in the following example:"
      ],
      "metadata": {
        "id": "IKK_sbpkhOzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "section_1 = {\"A\": 42, \"a list\": list(range(10)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "section_2 = {\"B\": 84, \"a list\": list(range(10)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "# Store the sections in a list which we pass to dump().\n",
        "\n",
        "with open(\"sections.json\", \"w\") as my_file:\n",
        "    json.dump([section_1, section_2], my_file)"
      ],
      "metadata": {
        "id": "QDW-_y6HhtRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then read back the entire structure in a single `load()`."
      ],
      "metadata": {
        "id": "ZG8HETZTiAO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the complete JSON file\n",
        "\n",
        "with open('sections.json', 'r') as my_file:\n",
        "    sections = json.load(my_file)\n",
        "\n",
        "# The sections are stored in the outer list\n",
        "\n",
        "print(sections)\n",
        "\n",
        "# Extract the individual sections\n",
        "\n",
        "section_1_copy = sections[0]\n",
        "section_2_copy = sections[1]\n",
        "\n",
        "print(section_1_copy)\n",
        "print(section_2_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGw0v1TTiFaY",
        "outputId": "d3eb4618-26f8-4599-d73a-5976ce2c1fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'A': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'a dict': {'a': 1, 'b': 2}}, {'B': 84, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'a dict': {'a': 1, 'b': 2}}]\n",
            "{'A': 42, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'a dict': {'a': 1, 'b': 2}}\n",
            "{'B': 84, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'a dict': {'a': 1, 'b': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like with pickle the json module can serialise to strings as well using the `dumps()` function."
      ],
      "metadata": {
        "id": "WeNvtHOoirAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNGtKK0tvWzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60597a09-8ce1-40e9-fcb4-c5a7dbef3e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON string content\n",
            "{\n",
            "    \"a dict\": {\n",
            "        \"a\": 1,\n",
            "        \"b\": 2\n",
            "    },\n",
            "    \"a list\": [\n",
            "        0,\n",
            "        1,\n",
            "        2,\n",
            "        3,\n",
            "        4,\n",
            "        5,\n",
            "        6,\n",
            "        7,\n",
            "        8,\n",
            "        9\n",
            "    ],\n",
            "    \"a number\": 42\n",
            "}\n",
            "Python data structure copy\n",
            "{'a dict': {'a': 1, 'b': 2}, 'a list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'a number': 42}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "my_data = {\"a number\": 42, \"a list\": list(range(10)), \"a dict\": {'a': 1, 'b': 2}}\n",
        "\n",
        "# Dump my_data to a JSON string\n",
        "\n",
        "my_data_dump = json.dumps(my_data, sort_keys=True, indent=4)\n",
        "\n",
        "print(\"JSON string content\")\n",
        "print(my_data_dump)\n",
        "\n",
        "# Read back data structure fron JSON string\n",
        "\n",
        "print(\"Python data structure copy\")\n",
        "my_data_copy = json.loads(my_data_dump)\n",
        "print(my_data_copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KFINDp8vWzN"
      },
      "source": [
        "## Pickle / JSON Comparison\n",
        "\n",
        "There are differences in the serialisation protocols. The example below compares performance and data complexity between the different methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5CfGpQevWzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f373253b-90af-43a4-bfa7-0ac903e780f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Pickle vs JSON Comparison ===\n",
            "Data complexity: 73667 characters when converted to string\n",
            "\n",
            "1. PICKLE FORMAT:\n",
            "  ✅ Save time: 0.0013 seconds\n",
            "  ✅ Load time: 0.0009 seconds\n",
            "  📦 File size: 43305 bytes\n",
            "  🔍 Data integrity: ✅ OK\n",
            "\n",
            "2. JSON FORMAT:\n",
            "  ✅ Save time: 0.0055 seconds\n",
            "  ✅ Load time: 0.0017 seconds\n",
            "  📦 File size: 73608 bytes\n",
            "  🔍 Data integrity: ✅ OK\n",
            "\n",
            "=== SUMMARY ===\n",
            "🏎️  Speed - Save: Pickle is faster\n",
            "🏎️  Speed - Load: Pickle is faster\n",
            "💾 Size: Pickle produces smaller files\n",
            "📖 Human readable: JSON ✅ | Pickle ❌\n",
            "🔧 Python-specific types: Pickle ✅ | JSON ❌\n",
            "🌐 Cross-language compatibility: JSON ✅ | Pickle ❌\n",
            "\n",
            "=== BEST PRACTICES ===\n",
            "🎯 Use PICKLE when:\n",
            "   • Working exclusively with Python\n",
            "   • Need to preserve exact Python object types\n",
            "   • Performance is critical\n",
            "   • Working with complex Python objects (classes, functions, etc.)\n",
            "\n",
            "🎯 Use JSON when:\n",
            "   • Need human-readable format\n",
            "   • Sharing data with other languages/systems\n",
            "   • Working with web APIs\n",
            "   • Data is relatively simple (dicts, lists, strings, numbers)\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Create test data of different types\n",
        "test_data = {\n",
        "    \"integers\": list(range(10000)),\n",
        "    \"strings\": [f\"string_{i}\" for i in range(1000)],\n",
        "    \"nested_dict\": {\n",
        "        \"level1\": {\n",
        "            \"level2\": {\n",
        "                \"data\": [1, 2, 3, 4, 5] * 50\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mixed_types\": [1, \"string\", [1, 2, 3], {\"key\": \"value\"}]\n",
        "}\n",
        "\n",
        "print(\"=== Pickle vs JSON Comparison ===\")\n",
        "print(f\"Data complexity: {len(str(test_data))} characters when converted to string\")\n",
        "\n",
        "# Test Pickle\n",
        "print(\"\\n1. PICKLE FORMAT:\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Save with pickle\n",
        "with open(\"test_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "pickle_save_time = time.time() - start_time\n",
        "pickle_size = Path(\"test_data.pkl\").stat().st_size\n",
        "\n",
        "# Load with pickle\n",
        "start_time = time.time()\n",
        "with open(\"test_data.pkl\", \"rb\") as f:\n",
        "    pickle_loaded = pickle.load(f)\n",
        "pickle_load_time = time.time() - start_time\n",
        "\n",
        "print(f\"  ✅ Save time: {pickle_save_time:.4f} seconds\")\n",
        "print(f\"  ✅ Load time: {pickle_load_time:.4f} seconds\")\n",
        "print(f\"  📦 File size: {pickle_size} bytes\")\n",
        "print(f\"  🔍 Data integrity: {'✅ OK' if pickle_loaded == test_data else '❌ FAILED'}\")\n",
        "\n",
        "# Test JSON (only for JSON-compatible data)\n",
        "json_compatible_data = {\n",
        "    \"integers\": list(range(10000)),\n",
        "    \"strings\": [f\"string_{i}\" for i in range(1000)],\n",
        "    \"nested_dict\": {\n",
        "        \"level1\": {\n",
        "            \"level2\": {\n",
        "                \"data\": [1, 2, 3, 4, 5] * 50\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n2. JSON FORMAT:\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Save with JSON\n",
        "with open(\"test_data.json\", \"w\") as f:\n",
        "    json.dump(json_compatible_data, f)\n",
        "\n",
        "json_save_time = time.time() - start_time\n",
        "json_size = Path(\"test_data.json\").stat().st_size\n",
        "\n",
        "# Load with JSON\n",
        "start_time = time.time()\n",
        "with open(\"test_data.json\", \"r\") as f:\n",
        "    json_loaded = json.load(f)\n",
        "json_load_time = time.time() - start_time\n",
        "\n",
        "print(f\"  ✅ Save time: {json_save_time:.4f} seconds\")\n",
        "print(f\"  ✅ Load time: {json_load_time:.4f} seconds\")\n",
        "print(f\"  📦 File size: {json_size} bytes\")\n",
        "print(f\"  🔍 Data integrity: {'✅ OK' if json_loaded == json_compatible_data else '❌ FAILED'}\")\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(f\"🏎️  Speed - Save: {'Pickle' if pickle_save_time < json_save_time else 'JSON'} is faster\")\n",
        "print(f\"🏎️  Speed - Load: {'Pickle' if pickle_load_time < json_load_time else 'JSON'} is faster\")\n",
        "print(f\"💾 Size: {'Pickle' if pickle_size < json_size else 'JSON'} produces smaller files\")\n",
        "print(f\"📖 Human readable: JSON ✅ | Pickle ❌\")\n",
        "print(f\"🔧 Python-specific types: Pickle ✅ | JSON ❌\")\n",
        "print(f\"🌐 Cross-language compatibility: JSON ✅ | Pickle ❌\")\n",
        "\n",
        "print(\"\\n=== BEST PRACTICES ===\")\n",
        "print(\"🎯 Use PICKLE when:\")\n",
        "print(\"   • Working exclusively with Python\")\n",
        "print(\"   • Need to preserve exact Python object types\")\n",
        "print(\"   • Performance is critical\")\n",
        "print(\"   • Working with complex Python objects (classes, functions, etc.)\")\n",
        "\n",
        "print(\"\\n🎯 Use JSON when:\")\n",
        "print(\"   • Need human-readable format\")\n",
        "print(\"   • Sharing data with other languages/systems\")\n",
        "print(\"   • Working with web APIs\")\n",
        "print(\"   • Data is relatively simple (dicts, lists, strings, numbers)\")\n",
        "\n",
        "# Cleanup\n",
        "Path(\"test_data.pkl\").unlink(missing_ok=True)\n",
        "Path(\"test_data.json\").unlink(missing_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzYPB-klk58h"
      },
      "source": [
        "---\n",
        "# Data archiving and compression\n",
        "\n",
        "In many application there is a need to package files and directories into archives such as tar- or zip-files. The runtime library of Python has built-in support for creating these types of archives. No need to have any external tools to accomplish this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNUUS_W4BjSN"
      },
      "source": [
        "## Tarfiles\n",
        "\n",
        "Tar-files or Tape Archive files are very common way of archiving a directory structure with associated files into a single file. A tar-file is also often compressed with gzip. This is full supported by the `tarfile` module.\n",
        "\n",
        "To be able to create som tar archives we first download some example files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCEs6g5oTbaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d3f332-8b4b-4857-ee26-229104362fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-20 20:05:39--  https://fossbytes.com/wp-content/uploads/2016/10/commodore64.jpg\n",
            "Resolving fossbytes.com (fossbytes.com)... 104.21.89.140, 172.67.160.54, 2606:4700:3037::6815:598c, ...\n",
            "Connecting to fossbytes.com (fossbytes.com)|104.21.89.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73687 (72K) [image/jpeg]\n",
            "Saving to: ‘bild1.jpg’\n",
            "\n",
            "bild1.jpg           100%[===================>]  71.96K   257KB/s    in 0.3s    \n",
            "\n",
            "2025-08-20 20:05:40 (257 KB/s) - ‘bild1.jpg’ saved [73687/73687]\n",
            "\n",
            "--2025-08-20 20:05:40--  https://ichef.bbci.co.uk/news/640/media/images/68628000/jpg/_68628283_apple-1.jpg\n",
            "Resolving ichef.bbci.co.uk (ichef.bbci.co.uk)... 23.220.188.130, 2600:1402:8000:a86::f33, 2600:1402:8000:a84::f33, ...\n",
            "Connecting to ichef.bbci.co.uk (ichef.bbci.co.uk)|23.220.188.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Cookie coming from ichef.bbci.co.uk attempted to set domain to bbc.co.uk\n",
            "Length: 45249 (44K) [image/jpeg]\n",
            "Saving to: ‘bild2.jpg’\n",
            "\n",
            "bild2.jpg           100%[===================>]  44.19K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-20 20:05:40 (2.67 MB/s) - ‘bild2.jpg’ saved [45249/45249]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://fossbytes.com/wp-content/uploads/2016/10/commodore64.jpg -O bild1.jpg\n",
        "!wget https://ichef.bbci.co.uk/news/640/media/images/68628000/jpg/_68628283_apple-1.jpg -O bild2.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the tarfile module we import it. We use the same convention as when importing Numpy. We import it as a short prefix `tf`."
      ],
      "metadata": {
        "id": "r6-sxxJkEVOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile as tf"
      ],
      "metadata": {
        "id": "yX2etY1FEj9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create an archive we create an instance of the `TarFile` class. It is very similar in how you create a file in Python. We give a filename and a parameter that determines if the archive should be written or read. We can then add files to the archive using the `.add()` method. It is also possible to create directories in the archive using the `makedir()` method."
      ],
      "metadata": {
        "id": "kD4HBPa_Erho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3ipY6B6k58i"
      },
      "outputs": [],
      "source": [
        "with tf.TarFile(\"myarchive.tar.gz\", \"w\") as mytar:\n",
        "\n",
        "    # Add a single file\n",
        "\n",
        "    mytar.add(\"bild1.jpg\")\n",
        "\n",
        "    # Add a file under the mydir directory\n",
        "\n",
        "    mytar.add(\"bild2.jpg\", arcname=\"mydir/bild1.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opening an archive is done in similar way by creating a TarFile instance in a with-statement. The filenames can be queried with the `.getnames()` method. More detailed information can be found by using the `.getmembers()` method which returns a list of TarInfo objects. These objects contain more detailded information on the stored files.\n",
        "\n",
        "Files can be extracted with the `.extract()` method. Please note the `filter=\"data\"` parameter. As archives can be potentially unsafe you can specify that it should only extract regular files or symlinks. This will become the default in Python 3.14. You can extract all files in the archive using the `.extractall()` method. The first parameter is the directory to unpack the archive in."
      ],
      "metadata": {
        "id": "fuK87ivhG26j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.TarFile(\"myarchive.tar.gz\", \"r\") as mytar:\n",
        "\n",
        "    # Query information about the archive\n",
        "\n",
        "    print(mytar.getnames())\n",
        "    print(mytar.getmembers())\n",
        "\n",
        "    # Extract a file and extract it under \"mytar\"\n",
        "\n",
        "    mytar.extract(\"bild1.jpg\", \"mytar\", filter=\"data\")\n",
        "\n",
        "    # Extract the entire archive in mytar_all\n",
        "\n",
        "    mytar.extractall(\"mytar_all\", filter=\"data\")\n",
        "    mytar.list(verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XWbhhVVEpZy",
        "outputId": "0859cf72-e4d8-4aea-f33f-4f4609a4b7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bild1.jpg', 'mydir/bild1.jpg']\n",
            "[<TarInfo 'bild1.jpg' at 0x78d590552680>, <TarInfo 'mydir/bild1.jpg' at 0x78d590552440>]\n",
            "?rw-r--r-- root/root      73687 2016-10-01 12:24:24 bild1.jpg \n",
            "?rw-r--r-- root/root      45249 2025-08-20 20:05:40 mydir/bild1.jpg \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we list the current diretory we get:"
      ],
      "metadata": {
        "id": "EDXoOsZJI9xR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESIUf8mmk58k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51526287-5d3e-462f-ea25-61e8022badd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 276\n",
            "drwxr-xr-x 1 root root   4096 Aug 20 20:11 .\n",
            "drwxr-xr-x 1 root root   4096 Aug 20 19:55 ..\n",
            "-rw-r--r-- 1 root root  73687 Oct  1  2016 bild1.jpg\n",
            "-rw-r--r-- 1 root root  45249 Aug 20 20:05 bild2.jpg\n",
            "drwxr-xr-x 4 root root   4096 Aug 19 13:37 .config\n",
            "-rw-r--r-- 1 root root 133120 Aug 20 20:10 myarchive.tar.gz\n",
            "drwxr-xr-x 2 root root   4096 Aug 20 20:11 mytar\n",
            "drwxr-xr-x 3 root root   4096 Aug 20 20:11 mytar_all\n",
            "drwxr-xr-x 1 root root   4096 Aug 19 13:38 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vscAuho1BmPa"
      },
      "source": [
        "## Zip-files\n",
        "\n",
        "Zip-files are archives that has a background on Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omnYDOank58n"
      },
      "outputs": [],
      "source": [
        "import zipfile as zf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with zf.ZipFile(\"myarchive.zip\", \"w\") as myzip:\n",
        "    myzip.write(\"bild1.jpg\")\n",
        "    myzip.write(\"bild2.jpg\")\n",
        "\n",
        "with zf.ZipFile(\"myarchive.zip\", \"r\") as myzip:\n",
        "    print(myzip.namelist())\n",
        "    print(myzip.getinfo(\"bild1.jpg\"))\n",
        "    myzip.extract(\"bild2.jpg\", \"myzip\")\n",
        "    myzip.extractall(\"myzip_all\")\n",
        "    myzip.printdir()\n",
        "    #with myzip.open(\"bild1.jpg\") as myfile:\n",
        "    #    image1 = plt.imread(myfile)\n",
        "    with myzip.open(\"bild2.jpg\") as myfile:\n",
        "        image2 = plt.imread(myfile)\n",
        "    #plt.imshow(image1)\n",
        "    plt.imshow(image2)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnsGIpEvk58t"
      },
      "source": [
        "---\n",
        "# Special file formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uajZWbZ3BVpF"
      },
      "source": [
        "## Configuration files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llYMf62dk58v"
      },
      "outputs": [],
      "source": [
        "config_file = \"\"\"[DEFAULT]\n",
        "ServerAliveInterval = 45\n",
        "Compression = yes\n",
        "CompressionLevel = 9\n",
        "ForwardX11 = yes\n",
        "\n",
        "[bitbucket.org]\n",
        "User = hg\n",
        "\n",
        "[topsecret.server.com]\n",
        "Port = 50022\n",
        "ForwardX11 = no\"\"\"\n",
        "\n",
        "\n",
        "with open(\"config1.ini\", \"w\") as f:\n",
        "    f.write(config_file)\n",
        "\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(\"config1.ini\")\n",
        "\n",
        "sections = config.sections()\n",
        "print(sections)\n",
        "\n",
        "print(config[\"bitbucket.org\"][\"user\"])\n",
        "\n",
        "for section in config.sections():\n",
        "    print(\"section =\", section)\n",
        "    keys = config[section].keys()\n",
        "    for key in keys:\n",
        "        print(key, \"=\", config[section][key])\n",
        "\n",
        "config[\"bitbucket.org\"][\"user\"] = \"jonas\"\n",
        "print(config[\"bitbucket.org\"][\"user\"])\n",
        "\n",
        "with open(\"config2.ini\", \"w\") as config_file:\n",
        "    config.write(config_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHVANkg8k58y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "\n",
        "config[\"DEFAULT\"] = {\n",
        "        \"Rating\":\"No rating\",\n",
        "        \"Length\":\"No length\"\n",
        "        }\n",
        "\n",
        "config[\"Dr Who\"] = {\"Rating\":\"9/9\"}\n",
        "config[\"Firefly\"] = {\"Length\":\"Too long\"}\n",
        "\n",
        "with open(\"config3.ini\", \"w\") as config_file:\n",
        "    config.write(config_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X651E6vVk585"
      },
      "outputs": [],
      "source": [
        "!cat config3.ini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnfL80ldBdGL"
      },
      "source": [
        "## Comma separated files - CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d_kqcMUU48h"
      },
      "outputs": [],
      "source": [
        "!rm example1.csv\n",
        "!wget https://raw.githubusercontent.com/jonaslindemann/guide_to_python/master/chapters/kapitel4/notebook/example1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTg4i19fk589"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('example1.csv', 'r') as csv_file:\n",
        "    csv_data = csv.reader(csv_file, delimiter=',')\n",
        "    for row in csv_data:\n",
        "        print(row)\n",
        "\n",
        "with open('example2.csv', 'w') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "    csv_writer.writerow(['Beteckning', 'Antal'])\n",
        "    csv_writer.writerow(['Gurka', '2'])\n",
        "    csv_writer.writerow(['Tomat', '4'])\n",
        "\n",
        "l = [[\"Beteckning\", \"Antal\"],[\"Gurka\", \"2\"], [\"Tomat\", \"4\"]]\n",
        "\n",
        "with open('example3.csv', 'w') as csv_file:\n",
        "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
        "    csv_writer.writerows(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywppH7juExIF"
      },
      "outputs": [],
      "source": [
        "!cat example1.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdpaCmJ2vWzP"
      },
      "source": [
        "# 🎯 Practical Exercises and Challenges\n",
        "\n",
        "Now that you've learned about Python's built-in functions and runtime library, here are some practical exercises to reinforce your understanding:\n",
        "\n",
        "## Exercise 1: System Information Tool 🖥️\n",
        "\n",
        "Create a Python script that gathers and displays system information:\n",
        "\n",
        "**Requirements:**\n",
        "- Display current working directory\n",
        "- Show environment variables (HOME/USERPROFILE, PATH, PYTHONPATH)\n",
        "- List files in current directory with their sizes\n",
        "- Show Python version and executable path\n",
        "- Display disk usage for current directory\n",
        "\n",
        "**Bonus:** Save the information to a JSON file with timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXB8RXVPvWzP"
      },
      "outputs": [],
      "source": [
        "# Exercise 1 Solution Template\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import platform\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "def create_system_info_tool():\n",
        "    \"\"\"Create a comprehensive system information tool\"\"\"\n",
        "\n",
        "    system_info = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"system\": {\n",
        "            \"platform\": platform.system(),\n",
        "            \"platform_version\": platform.version(),\n",
        "            \"architecture\": platform.architecture()[0],\n",
        "            \"processor\": platform.processor() or \"Unknown\"\n",
        "        },\n",
        "        \"python\": {\n",
        "            \"version\": sys.version,\n",
        "            \"executable\": sys.executable,\n",
        "            \"path\": sys.path[:3]  # First 3 entries to avoid clutter\n",
        "        },\n",
        "        \"directories\": {\n",
        "            \"current_working_directory\": os.getcwd(),\n",
        "            \"home_directory\": os.path.expanduser(\"~\"),\n",
        "            \"temp_directory\": os.path.dirname(tempfile.gettempdir())\n",
        "        },\n",
        "        \"environment\": {\n",
        "            \"PATH\": os.environ.get(\"PATH\", \"Not found\")[:100] + \"...\",  # Truncated\n",
        "            \"PYTHONPATH\": os.environ.get(\"PYTHONPATH\", \"Not set\"),\n",
        "            \"USER\": os.environ.get(\"USER\") or os.environ.get(\"USERNAME\", \"Unknown\")\n",
        "        },\n",
        "        \"current_directory_contents\": []\n",
        "    }\n",
        "\n",
        "    # TODO: Complete this function\n",
        "    # Add code to:\n",
        "    # 1. List files in current directory with sizes\n",
        "    # 2. Calculate total directory size\n",
        "    # 3. Save to JSON file\n",
        "\n",
        "    print(\"📊 System Information Tool\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"🖥️  System:\", system_info[\"system\"][\"platform\"])\n",
        "    print(\"🐍 Python:\", sys.version.split()[0])\n",
        "    print(\"📁 Working Dir:\", system_info[\"directories\"][\"current_working_directory\"])\n",
        "\n",
        "    return system_info\n",
        "\n",
        "# Run the tool\n",
        "info = create_system_info_tool()\n",
        "\n",
        "# Your task: Complete the implementation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FotgkL9vvWzP"
      },
      "source": [
        "## Exercise 2: Log File Analyzer 📋\n",
        "\n",
        "Create a program that analyzes log files and generates reports:\n",
        "\n",
        "**Requirements:**\n",
        "- Read log files with different severity levels\n",
        "- Count occurrences of each log level\n",
        "- Find the most common error messages\n",
        "- Generate a summary report\n",
        "- Save results in both JSON and CSV formats\n",
        "\n",
        "**Sample log format:**\n",
        "```\n",
        "2025-08-19 10:30:15 | INFO     | User login successful: alice\n",
        "2025-08-19 10:31:22 | WARNING  | Slow query detected: SELECT * FROM users\n",
        "2025-08-19 10:32:45 | ERROR    | Database connection failed\n",
        "```\n",
        "\n",
        "## Exercise 3: Backup Utility 💾\n",
        "\n",
        "Build a simple backup utility:\n",
        "\n",
        "**Requirements:**\n",
        "- Create compressed archives of specified directories\n",
        "- Support both ZIP and TAR formats\n",
        "- Include timestamp in backup filename\n",
        "- Log backup operations\n",
        "- Verify backup integrity after creation\n",
        "- Clean up old backups (keep only last N backups)\n",
        "\n",
        "## Exercise 4: Configuration Manager ⚙️\n",
        "\n",
        "Create a configuration management system:\n",
        "\n",
        "**Requirements:**\n",
        "- Read configuration from INI files\n",
        "- Provide default values for missing settings\n",
        "- Validate configuration values\n",
        "- Support environment variable overrides\n",
        "- Save modified configurations back to file\n",
        "- Support both development and production configs\n",
        "\n",
        "## Challenge: Process Monitor 🔍\n",
        "\n",
        "**Advanced Challenge:** Create a process monitoring tool that:\n",
        "\n",
        "1. Lists running processes (use `subprocess` with system commands)\n",
        "2. Monitors CPU and memory usage\n",
        "3. Logs process information periodically\n",
        "4. Sends alerts when processes exceed thresholds\n",
        "5. Stores historical data in JSON format\n",
        "6. Generates summary reports\n",
        "\n",
        "**Bonus Features:**\n",
        "- Web dashboard using simple HTTP server\n",
        "- Email notifications for critical alerts\n",
        "- Configuration via INI files\n",
        "- Automatic log rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shybhBEvWzP"
      },
      "source": [
        "# 📚 Summary and Best Practices\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "### 🏗️ **System Operations**\n",
        "- **Always use try-except blocks** when working with file systems\n",
        "- **Prefer `pathlib.Path`** over `os.path` for modern Python (3.4+)\n",
        "- **Use context managers** (`with` statements) for file operations\n",
        "- **Check for cross-platform compatibility** when using system commands\n",
        "\n",
        "### 🔧 **Process Management**\n",
        "- **Use `subprocess.run()`** for simple command execution\n",
        "- **Always set timeouts** to prevent hanging processes\n",
        "- **Capture both stdout and stderr** for proper error handling\n",
        "- **Use `text=True`** to work with strings instead of bytes\n",
        "\n",
        "### 📝 **Logging Best Practices**\n",
        "- **Configure logging early** in your application\n",
        "- **Use appropriate log levels**: DEBUG < INFO < WARNING < ERROR < CRITICAL\n",
        "- **Include meaningful context** in log messages\n",
        "- **Use structured logging** with consistent formatting\n",
        "- **Consider log rotation** for production applications\n",
        "\n",
        "### 💾 **Data Serialization Guidelines**\n",
        "\n",
        "| Format | Use When | Pros | Cons |\n",
        "|--------|----------|------|------|\n",
        "| **JSON** | Web APIs, config files, cross-language | Human readable, widely supported | Limited data types |\n",
        "| **Pickle** | Python-only, complex objects | Preserves Python types, fast | Not human readable, Python-specific |\n",
        "| **CSV** | Tabular data, Excel compatibility | Simple, widely supported | Limited structure |\n",
        "| **INI** | Configuration files | Human readable, simple | Limited nesting |\n",
        "\n",
        "### 🗜️ **Compression and Archives**\n",
        "- **Use ZIP** for cross-platform compatibility\n",
        "- **Use TAR.GZ** for better compression on Unix systems\n",
        "- **Always verify** archive integrity after creation\n",
        "- **Consider compression level** vs. speed trade-offs\n",
        "\n",
        "## 🚨 Common Pitfalls to Avoid\n",
        "\n",
        "1. **Not handling exceptions** when working with files/processes\n",
        "2. **Forgetting to close resources** (use `with` statements!)\n",
        "3. **Hard-coding file paths** (use `os.path.join()` or `pathlib`)\n",
        "4. **Not validating user input** before passing to system commands\n",
        "5. **Ignoring return codes** from subprocess operations\n",
        "6. **Not setting timeouts** for external processes\n",
        "7. **Using deprecated functions** (`os.system()` instead of `subprocess`)\n",
        "8. **Not considering security** when executing external commands\n",
        "\n",
        "## 🎯 Production Readiness Checklist\n",
        "\n",
        "- [ ] **Error handling**: All operations wrapped in try-except\n",
        "- [ ] **Logging**: Comprehensive logging with appropriate levels\n",
        "- [ ] **Configuration**: Externalized configuration files\n",
        "- [ ] **Security**: Input validation and safe command execution\n",
        "- [ ] **Performance**: Timeouts and resource management\n",
        "- [ ] **Monitoring**: Process monitoring and health checks\n",
        "- [ ] **Documentation**: Clear docstrings and comments\n",
        "- [ ] **Testing**: Unit tests for critical functionality\n",
        "\n",
        "## 🔗 Further Learning Resources\n",
        "\n",
        "- **Official Documentation**: [Python Standard Library](https://docs.python.org/3/library/)\n",
        "- **PEP 8**: Python Style Guide\n",
        "- **Real Python**: Tutorials on system programming\n",
        "- **Automate the Boring Stuff**: Practical Python programming\n",
        "- **Effective Python**: Advanced best practices\n",
        "\n",
        "---\n",
        "\n",
        "## 🎉 Congratulations!\n",
        "\n",
        "You've completed the Python Built-in Functions and Runtime Library guide! You now have the knowledge to:\n",
        "\n",
        "- ✅ Interact with the operating system programmatically\n",
        "- ✅ Manage files, directories, and processes\n",
        "- ✅ Implement robust logging and error handling\n",
        "- ✅ Work with various data formats and compression\n",
        "- ✅ Build production-ready Python applications\n",
        "\n",
        "**Next Steps:** Try the exercises above and start building your own system utilities!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}